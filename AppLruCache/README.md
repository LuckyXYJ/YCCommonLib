# Lru内存缓存
#### 目录介绍
- 01.基础概念介绍
- 02.常见思路和做法
- 03.Api调用说明
- 04.遇到的坑分析
- 05.其他问题说明



### 01.基础概念说明
#### 1.1 内存缓存介绍


#### 1.2 LruCache核心思想
- LRU是近期最少使用的算法，它的核心思想是当缓存满时，会优先淘汰那些近期最少使用的缓存对象。
    - ![image](https://img-blog.csdnimg.cn/20210207165359999.png)
- LruCache的淘汰策略简单说明
    - 将LinkedHashMap中的默认顺序设置为访问顺序，每次调用get，则将该对象移到链表的头部，调用put插入新的对象到链表头部。
    - 当内存缓存达到最大值时，就将链表尾部的对象移除。每次put或者remove，都需要判断缓存大小是否足够trimToSize。




### 02.常见思路和做法


### 03.Api调用说明



### 04.遇到的坑分析


### 05.其他问题说明





